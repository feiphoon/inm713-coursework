"""
Based heavily on code for lab6 of INM713.
Created on 05 March 2021
@author: ejimenez-ruiz
"""
import rdflib
from rdflib import Graph, Namespace, URIRef, Literal
from rdflib.namespace import RDF, XSD, RDFS
from rdflib.util import guess_format
import owlrl

import time
import pandas as pd
from pandas.core.frame import DataFrame
from unidecode import unidecode

from typing import Dict, Optional, Any

from pprint import pprint


class TabToGraph:
    def __init__(self, input_filepath: str, namespace_str: str, prefix: str) -> None:
        self.input_filepath: str = input_filepath
        self.namespace_str: str = namespace_str
        self.prefix: str = prefix

        # Initialise graph
        self.graph: rdflib.Graph = Graph()

        # Special Namespace class to directly create URIRefs
        self.namespace: rdflib.Namespace = Namespace(self.namespace_str)

        # Bind namespace
        self.graph.bind(self.prefix, self.namespace)

        # Load input as dataframe
        # TODO: consider using usecols here
        # TODO: datatypes along with that
        self.data_df: pd.DataFrame = pd.read_csv(input_filepath, encoding="utf-8")

        # Dictionary to store URIs
        self.string_to_uri: dict = {}

    @staticmethod
    def apply_preprocessing(
        df: pd.DataFrame, target_col: str, transformed_col: Optional[str]
    ) -> None:
        """
        A bit crude and does a lot of stuff, but it will do for now.
        Note, have tested all the bad characters in this dataset and
        how tolerant the URI creation is = there are some dangerous
        things like # and /, but it breaks on pipe character |.
        """
        # If no new col is named to hold transformations,
        # then the transformations should be in-place.
        if not transformed_col:
            print(
                "WARNING: transformed_col name not supplied, transformations will be applied in-place."
            )
            transformed_col = target_col

        # Normalise unicode/accented characters,
        # e.g. cafÃ© becomes cafe.
        # TODO: buggy
        df[transformed_col] = df[target_col].apply(unidecode)

        # Check unique characters in menu item column
        unique_chars: list = list(set(df[transformed_col].sum()))

        non_alphanum_chars: list = [
            _ for _ in unique_chars if (not _.isalnum()) and (_ != " ")
        ]

        # Target some known troublemakers
        if "@" in non_alphanum_chars:
            df[transformed_col] = df[transformed_col].str.replace(
                "@", "at", regex=False
            )
            non_alphanum_chars.remove("@")

        if "&" in non_alphanum_chars:
            df[transformed_col] = df[transformed_col].str.replace(
                "&", "and", regex=False
            )
            non_alphanum_chars.remove("&")

        if "+" in non_alphanum_chars:
            df[transformed_col] = df[transformed_col].str.replace(
                "+", "and", regex=False
            )
            non_alphanum_chars.remove("+")

        # Remove sketchy characters
        for _ in non_alphanum_chars:
            df[transformed_col] = df[transformed_col].str.replace(_, "", regex=False)

        # Collapse remaining double whitespace,
        # possibly resulting from character removals.
        # E.g "Bonnie & Clyde" -> "Bonnie  Clyde"
        df[transformed_col] = df[transformed_col].str.replace(r" +", " ", regex=True)

    @staticmethod
    def replace_missing_values(
        df: DataFrame,
        target_col: str,
        transformed_col: Optional[str],
        fillna_value: Any,
    ) -> None:
        # If no new col is named to hold transformations,
        # then the transformations should be in-place.
        if not transformed_col:
            print(
                "WARNING: transformed_col name not supplied, transformations will be applied in-place."
            )
            transformed_col = target_col
        df[transformed_col] = df[target_col].fillna(fillna_value)

    def convert_csv_to_rdf(self) -> None:
        """
        Subtask RDF.2
        """
        tic = time.perf_counter()

        # Add some subclasses
        self.graph.add(
            (self.namespace.Restaurant, RDFS.subClassOf, self.namespace.Location)
        )
        self.graph.add((self.namespace.Location, RDFS.subClassOf, self.namespace.Place))
        self.graph.add((self.namespace.City, RDFS.subClassOf, self.namespace.Place))
        self.graph.add((self.namespace.Country, RDFS.subClassOf, self.namespace.Place))

        if "country" in self.data_df:
            self.mapping_to_create_type_triple(
                subject_col="country", class_type=self.namespace.Country
            )

            self.mapping_to_create_literal_triple(
                subject_col="country",
                object_col="country",
                predicate=self.namespace.name,
                datatype=RDF.PlainLiteral,
            )

        if "currency" in self.data_df:
            self.mapping_to_create_type_triple(
                subject_col="currency", class_type=self.namespace.Currency
            )

            self.mapping_to_create_literal_triple(
                subject_col="currency",
                object_col="currency",
                predicate=self.namespace.name,
                datatype=RDF.PlainLiteral,
            )

            self.mapping_to_create_object_triple(
                subject_col="currency",
                object_col="country",
                predicate=self.namespace.isCurrencyOf,
            )

        if "city" in self.data_df:

            self.mapping_to_create_type_triple(
                subject_col="city", class_type=self.namespace.City
            )

            self.mapping_to_create_literal_triple(
                subject_col="city",
                object_col="city",
                predicate=self.namespace.name,
                datatype=RDF.PlainLiteral,
            )

        if "name" in self.data_df:
            # TODO: preprocessing
            self.apply_preprocessing(
                df=self.data_df, target_col="name", transformed_col="cleaned_name"
            )

            # We give subject column and target type
            self.mapping_to_create_type_triple(
                subject_col="cleaned_name", class_type=self.namespace.Restaurant
            )

            self.mapping_to_create_literal_triple(
                subject_col="cleaned_name",
                object_col="name",
                predicate=self.namespace.name,
                datatype=RDF.PlainLiteral,
            )

            # TODO: Check if using RDF.PlainLiteral here is correct
            # Instead of XSD: primitive datatypes
            if "address" in self.data_df:
                self.mapping_to_create_literal_triple(
                    subject_col="cleaned_name",
                    object_col="address",
                    predicate=self.namespace.address,
                    datatype=RDF.PlainLiteral,
                )

            if "postcode" in self.data_df:
                self.mapping_to_create_literal_triple(
                    subject_col="cleaned_name",
                    object_col="postcode",
                    predicate=self.namespace.postcode,
                    datatype=XSD.string,
                )

            if "state" in self.data_df:
                self.mapping_to_create_literal_triple(
                    subject_col="cleaned_name",
                    object_col="state",
                    predicate=self.namespace.state,
                    datatype=XSD.string,
                )

            if "categories" in self.data_df:
                self.mapping_to_create_literal_triple(
                    subject_col="cleaned_name",
                    object_col="categories",
                    predicate=self.namespace.categories,
                    datatype=RDF.PlainLiteral,
                )

            self.mapping_to_create_object_triple(
                subject_col="cleaned_name",
                object_col="city",
                predicate=self.namespace.isPlaceInCity,
            )

            self.mapping_to_create_object_triple(
                subject_col="city",
                object_col="country",
                predicate=self.namespace.isPlaceInCountry,
            )

        if "name" in self.data_df and "menu item" in self.data_df:
            # Tidy weird characters from menu item column first
            self.apply_preprocessing(
                df=self.data_df,
                target_col="menu item",
                transformed_col="cleaned_menu_item",
            )

            # Make each item unique to the restaurant
            self.data_df["restaurant_name_menu_item"] = self.data_df[
                "cleaned_name"
            ].str.cat(self.data_df["cleaned_menu_item"], " ")

            # Create the menu item
            self.mapping_to_create_type_triple(
                subject_col="restaurant_name_menu_item",
                class_type=self.namespace.MenuItem,
            )

            self.mapping_to_create_object_triple(
                subject_col="restaurant_name_menu_item",
                object_col="cleaned_name",
                predicate=self.namespace.isMenuItemAt,
            )

            self.mapping_to_create_literal_triple(
                subject_col="restaurant_name_menu_item",
                object_col="cleaned_menu_item",
                predicate=self.namespace.name,
                datatype=RDF.PlainLiteral,
            )

            self.mapping_to_create_literal_triple(
                subject_col="restaurant_name_menu_item",
                object_col="item value",
                predicate=self.namespace.menu_item_price,
                datatype=XSD.decimal,
            )

            self.mapping_to_create_literal_triple(
                subject_col="restaurant_name_menu_item",
                object_col="currency",
                predicate=self.namespace.menu_item_price_currency,
                datatype=RDF.PlainLiteral,
            )

            self.mapping_to_create_literal_triple(
                subject_col="restaurant_name_menu_item",
                object_col="item description",
                predicate=self.namespace.menu_item_description,
                datatype=RDF.PlainLiteral,
            )

            toc = time.perf_counter()
            print(f"Finished in {toc - tic} seconds.")
            print(f"Extracted {len(self.graph)} triples.")

    @staticmethod
    def is_object_missing(value: str):
        """
        First is a check for NaN when the subject value
        could be a string (so can't use math.isnan())
        """
        return (value != value) or (value is None) or (value == "")

    def createURIForEntity(self, entity_name: str) -> Dict[str, str]:
        # We create fresh URI (default option)
        self.string_to_uri[entity_name] = self.namespace_str + entity_name.replace(
            " ", "_"
        )

        # if useExternalURI:  # We connect to online KG
        #     uri = self.getExternalKGURI(name)
        #     if uri != "":
        #         self.stringToURI[name] = uri

        return self.string_to_uri[entity_name]

    def mapping_to_create_type_triple(
        self, subject_col: str, class_type: rdflib.term.URIRef
    ) -> None:
        """
        TODO: Mapping to create triples like lab6:London rdf:type lab6:City
        A mapping may create more than one triple
        column: columns where the entity information is stored
        TODO: useExternalURI: if URI is fresh or from external KG
        """
        for subject in self.data_df[subject_col]:
            if self.is_object_missing(subject):
                return
            else:
                entity_uri: str = None
                subject = subject.lower()

                # We use the ascii name to create the fresh URI for a city in the dataset
                if subject in self.string_to_uri:
                    entity_uri = self.string_to_uri[subject]
                else:
                    entity_uri = self.createURIForEntity(subject)
                # else:
                #     entity_uri = self.createURIForEntity(subject.lower(), useExternalURI)

                # TYPE TRIPLE
                # For the individuals we use URIRef to create an object "URI" out of the string URIs
                # For the concepts we use the ones in the ontology and we are using the NameSpace class
                # Alternatively one could use URIRef(self.lab6_ns_str+"City") for example
                self.graph.add((URIRef(entity_uri), RDF.type, class_type))

    def mapping_to_create_literal_triple(
        self,
        subject_col: str,
        object_col: str,
        predicate: rdflib.term.URIRef,
        datatype: str,
    ) -> None:
        """
        TODO: Mappings to create triples of the form lab6:london lab6:name "London"
        """
        for subject, lit_value in zip(
            self.data_df[subject_col], self.data_df[object_col]
        ):

            # Make sure this does nothing when the object is missing
            if self.is_object_missing(value=lit_value):
                return

            else:
                subject = subject.lower()
                # Use already created URI
                entity_uri = self.string_to_uri[subject]

                # Literal
                literal = Literal(lit_value, datatype=datatype)

                # Add new literal triple to graph
                self.graph.add((URIRef(entity_uri), predicate, literal))

    def mapping_to_create_object_triple(
        self, subject_col: str, object_col: str, predicate: rdflib.term.URIRef
    ) -> None:
        """
        Mappings to create triples of the form fp:Bend fp:isLocatedInCountry fp:USA
        """
        for subject, object in zip(self.data_df[subject_col], self.data_df[object_col]):
            # Make sure this does nothing when the object is missing
            if self.is_object_missing(value=subject) or self.is_object_missing(
                value=object
            ):
                return

            else:
                # Use already created URI
                subject_uri = self.string_to_uri[subject.lower()]
                object_uri = self.string_to_uri[object.lower()]

                # New triple
                self.graph.add((URIRef(subject_uri), predicate, URIRef(object_uri)))

    def perform_reasoning(self, ontology_file: str) -> None:
        """
        Expand the graph with the inferred triples.
        """
        # print(guess_format(ontology_file))
        self.graph.load(ontology_file, format=guess_format(ontology_file))

        print(f"Triples including ontology: {len(self.graph)}.")

        # We apply reasoning and expand the graph with new triples
        owlrl.DeductiveClosure(
            owlrl.OWLRL_Semantics, axiomatic_triples=False, datatype_axioms=False
        ).expand(self.graph)

        print(f"Triples after OWL 2 RL reasoning: {len(self.graph)}.")

    def debug(self) -> None:
        pprint(vars(self))

    def print(self, nrows: int = None) -> None:
        if not nrows:
            nrows = len(self.graph)

        for s, p, o in self.graph[:nrows]:
            print((s.n3(), p.n3(), o.n3()))

        print(f"Printed {len(self.graph)} triples.")

    def save_graph(self, output_file: str) -> None:
        # TODO: check what the first line does
        # print(self.g.serialize(format="turtle").decode("utf-8"))
        self.graph.serialize(destination=output_file, format="ttl")


if __name__ == "__main__":
    INPUT_FILEPATH: str = "../data/INM713_coursework_data_pizza_8358_1_reduced.csv"
    # INPUT_FILEPATH = "../data/data_pizza_spike.csv"
    NAMESPACE: str = Namespace("http://www.city.ac.uk/ds/inm713/feiphoon#")
    PREFIX: str = "fp"

    tab_to_graph = TabToGraph(
        input_filepath=INPUT_FILEPATH, namespace_str=NAMESPACE, prefix=PREFIX
    )

    tab_to_graph.convert_csv_to_rdf()

    # tab_to_graph.debug()
    # tab_to_graph.print()

    # Graph with only data
    tab_to_graph.save_graph(output_file="pizza_restaurants_without_reasoning.ttl")

    # Apply OWL 2 RL reasoning
    tab_to_graph.perform_reasoning(
        "../1-OWL/pizza_restaurant_ontology5-slim.ttl"
    )  # ttl format
    # # tab_to_graph.perform_reasoning("../data/pizza_restaurant_ontology5-slim.owl") ##owl (rdf/xml) format

    # # Graph with ontology triples and entailed triples
    tab_to_graph.save_graph("pizza_restaurants_with_reasoning.ttl")

    # # SPARQL results into CSV
    # solution.performSPARQLQuery(file.replace(".csv", "-" + task) + "-query-results.csv")

    # # SPARQL for Lab 7
    # solution.performSPARQLQueryLab7()
